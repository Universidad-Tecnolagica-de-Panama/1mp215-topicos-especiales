{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb08479",
   "metadata": {},
   "source": [
    "# Asignación 1: Implementando y Analizando KNN desde Cero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ddd5f",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "- Familiarizarse con conceptos y habilidades básicas de programación en Python aplicadas a ciencia de datos.\n",
    "- Comprender el funcionamiento del algoritmo K-Nearest Neighbors (KNN) a través de su implementación desde cero.\n",
    "- Cargar, explorar y preparar el dataset Pima Indian Diabetes para tareas de clasificación.\n",
    "- Implementar funciones fundamentales como la distancia euclidiana y la predicción de clases usando KNN.\n",
    "- Comparar la implementación propia de KNN con la versión de scikit-learn, analizando similitudes y diferencias en los resultados.\n",
    "- Analizar el impacto del parámetro **k** en el desempeño del clasificador y discutir los hallazgos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205e5f1f",
   "metadata": {},
   "source": [
    "## Preámbulo: **Pima Indian Diabetes Dataset**\n",
    "\n",
    "El **Pima Indian Diabetes Dataset** es un conjunto de datos clásico en Machine Learning y estadística, utilizado principalmente para problemas de clasificación binaria. Contiene información médica de mujeres de origen Pima (una población indígena de América del Norte) mayores de 21 años. Cada registro incluye variables como número de embarazos, concentración de glucosa en plasma, presión arterial, grosor del pliegue cutáneo, niveles de insulina, índice de masa corporal (IMC), función hereditaria de la diabetes y edad. El objetivo es predecir si una persona tiene o no diabetes (variable objetivo binaria).\n",
    "\n",
    "Un aspecto importante de este dataset es la presencia de valores faltantes, especialmente en variables como glucosa, presión arterial, grosor del pliegue cutáneo e insulina, donde valores igual a cero suelen indicar datos ausentes. Para esta asignación, se utilizará una versión limpia del dataset en la que se han eliminado los registros con valores faltantes, permitiendo así un análisis más directo y sin la necesidad de imputación de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257473",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar y explorar el dataset\n",
    "\n",
    "**Instrucciones:**\n",
    "- Descarga el dataset desde el repositorio de GitHub del curso. El archivo se encuentra en `datasets/pima_indian_diabetes_dataset/cleaned_dataset.csv`.\n",
    "- Carga el dataset utilizando pandas.\n",
    "- Muestra las primeras filas (`df.head()`) del dataset.\n",
    "- Imprime la cantidad total de filas y columnas del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86bb59fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1633b9",
   "metadata": {},
   "source": [
    "## Paso 2: Crear función para cargar y dividir el dataset\n",
    "\n",
    "**Instrucciones:**\n",
    "- Implementa una función en Python que:\n",
    "  - Cargue el dataset limpio desde la ruta especificada.\n",
    "  - Seleccione las primeras 10 muestras como conjunto de entrenamiento.\n",
    "  - Seleccione las siguientes 10 muestras como conjunto de prueba.\n",
    "  - Devuelva por separado: `X_train`, `y_train`, `X_test`, `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd24c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa9494c",
   "metadata": {},
   "source": [
    "## Paso 3: Implementar la función de distancia euclidiana\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función en Python que reciba dos vectores y calcule la distancia euclidiana entre ellos.\n",
    "- Utiliza la siguiente fórmula matemática para la distancia euclidiana entre dos vectores $x$ y $y$ de $n$ dimensiones:\n",
    "\n",
    "$$\n",
    "d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$\n",
    "\n",
    "- Prueba tu función con los siguientes dos ejemplos (cada vector corresponde a una fila del dataset):\n",
    "\n",
    "| Pregnancies | Glucose | Blood Pressure | Skin Thickness | Insulin | BMI  | Diabetes Pedigree Function | Age | Outcome |\n",
    "|-------------|---------|---------------|----------------|---------|------|----------------------------|-----|---------|\n",
    "|      1      |   106   |      70       |      28        |   135   | 34.2 |           0.142            | 22  |    0    |\n",
    "|      2      |   102   |      86       |      36        |   120   | 45.5 |           0.127            | 23  |    1    |\n",
    "\n",
    "- Calcula la distancia euclidiana a mano y luego verifica que el resultado de tu función sea el mismo.\n",
    "- La función debe imprimir el resultado del cálculo de la distancia euclidiana con los datos presentados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1607f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4124e762",
   "metadata": {},
   "source": [
    "## Paso 4: Implementar un clasificador KNN básico\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función que, dado un punto de prueba, calcule la distancia a todos los puntos de entrenamiento utilizando tu función de distancia euclidiana.\n",
    "- Selecciona los **k = 3** vecinos más cercanos y predice la clase mayoritaria entre ellos.\n",
    "- Aplica tu función a las 10 muestras de prueba obtenidas previamente, utilizando las 10 muestras de entrenamiento como referencia.\n",
    "- El script debe imprimir una tabla comparando el valor real de `Outcome` de cada muestra de prueba con el valor predicho por tu algoritmo.\n",
    "- Considere que las tablas se pueden codificar con un formato similar al que se muestra en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61382533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestra  Outcome_real  Predicho\n",
      "1        0             0       \n",
      "2        1             1       \n",
      "3        0             0       \n",
      "4        1             1       \n",
      "5        0             1       \n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de tabla simple usando print y formato alineado\n",
    "print(\"{:<8} {:<13} {:<8}\".format(\"Muestra\", \"Outcome_real\", \"Predicho\"))\n",
    "print(\"{:<8} {:<13} {:<8}\".format(1, 0, 0))\n",
    "print(\"{:<8} {:<13} {:<8}\".format(2, 1, 1))\n",
    "print(\"{:<8} {:<13} {:<8}\".format(3, 0, 0))\n",
    "print(\"{:<8} {:<13} {:<8}\".format(4, 1, 1))\n",
    "print(\"{:<8} {:<13} {:<8}\".format(5, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41db18b",
   "metadata": {},
   "source": [
    "## Paso 5: Comparar con scikit-learn\n",
    "\n",
    "**Instrucciones:**\n",
    "- Utiliza `KNeighborsClassifier` de scikit-learn para entrenar y predecir sobre el mismo subconjunto de datos. Asegúrate de definir los hiperparámetros: `k=3`, distancia euclidiana y método de búsqueda fuerza bruta (`algorithm='brute'`).\n",
    "- Compara los resultados de tu implementación con los obtenidos por scikit-learn.\n",
    "- El script debe mostrar una tabla que compare el valor real de `Outcome` de cada muestra de prueba, el valor predicho por tu algoritmo y el valor predicho por scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635f08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c2b79",
   "metadata": {},
   "source": [
    "## Paso 6: Normalización de los datos\n",
    "\n",
    "Hasta ahora, se han utilizado los datos crudos directamente desde el dataset. Sin embargo, en Machine Learning es una buena práctica normalizar o escalar los datos antes de aplicar algoritmos basados en distancias, como KNN. La normalización ayuda a que todas las variables tengan el mismo rango y evita que aquellas con valores numéricos grandes dominen el cálculo de distancias.\n",
    "\n",
    "**Instrucciones:**\n",
    "- Implementa una nueva función de carga de datos, similar a la del Paso 2, que:\n",
    "  - Cargue el dataset limpio desde la ruta especificada.\n",
    "  - Seleccione las primeras 10 muestras como conjunto de entrenamiento y las siguientes 10 como conjunto de prueba.\n",
    "  - Aplique un escalado Min-Max (`MinMaxScaler` de scikit-learn) a las 20 muestras seleccionadas, considerando el minimo y el maximo de ambos conjuntos.\n",
    "  - Devuelva los conjuntos `X_train`, `y_train`, `X_test`, `y_test` ya normalizados.\n",
    "- Utiliza estos datos normalizados para volver a comparar el desempeño de tu implementación de KNN y la de scikit-learn, como en el Paso 5.\n",
    "- Presenta los resultados en una tabla comparativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba97ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7437a",
   "metadata": {},
   "source": [
    "## Paso 7: Analizar el impacto de k\n",
    "\n",
    "**Instrucciones:**\n",
    "- Evalúa el desempeño de tu implementación personalizada para distintos valores de **k** (por ejemplo: 1, 3, 5, 7, 9).\n",
    "- Utiliza los datos normalizados\n",
    "- Para cada valor de k, predice el `Outcome` de las muestras de prueba.\n",
    "- Construye una tabla que muestre, para cada muestra de prueba, el número de muestra, el valor real de `Outcome` y los valores predichos por tu algoritmo para cada valor de k. Por ejemplo:\n",
    "\n",
    "| Muestra | Outcome real | k=1 | k=3 | k=5 | k=7 | k=9 |\n",
    "|---------|--------------|-----|-----|-----|-----|-----|\n",
    "|    1    |      0       |  0  |  0  |  1  |  0  |  0  |\n",
    "|    2    |      1       |  1  |  1  |  0  |  1  |  1  |\n",
    "|    3    |      0       |  0  |  0  |  0  |  0  |  1  |\n",
    "|    4    |      1       |  1  |  0  |  1  |  1  |  1  |\n",
    "|    5    |      0       |  0  |  1  |  0  |  0  |  0  |\n",
    "|    6    |      1       |  1  |  1  |  1  |  1  |  1  |\n",
    "|    7    |      0       |  0  |  0  |  0  |  1  |  0  |\n",
    "|    8    |      1       |  1  |  1  |  1  |  1  |  1  |\n",
    "|    9    |      0       |  0  |  0  |  1  |  0  |  0  |\n",
    "|   10    |      1       |  1  |  1  |  1  |  1  |  1  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6314a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37fdf1a",
   "metadata": {},
   "source": [
    "# Rúbrica de Evaluación\n",
    "\n",
    "| Paso                                                         | Puntos |\n",
    "|--------------------------------------------------------------|--------|\n",
    "| 1. Cargar y explorar el dataset                              |   10   |\n",
    "| 2. Crear función para cargar y dividir el dataset            |   10   |\n",
    "| 3. Implementar la función de distancia euclidiana            |   10   |\n",
    "| 4. Implementar un clasificador KNN básico                    |   10   |\n",
    "| 5. Comparar con scikit-learn                                 |   20   |\n",
    "| 6. Normalización y comparación con KNN y scikit-learn        |   20   |\n",
    "| 7. Analizar el impacto de k                                  |   20   |\n",
    "| **Total**                                                    | **100**|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
